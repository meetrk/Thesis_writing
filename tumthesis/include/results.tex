\chapter{Results}
\label{chap:results}

\section{Experiment 1: Regularization Impact}
\label{sec:experiment_1_regularization_impact}
This section presents the results of Experiment 1, which investigates the impact of different regularization techniques on the performance and uncertainty estimation of RGCN model. We compare the baseline model with models employing edge dropout, label smoothing, and a combination of both techniques.


\subsection{Link Prediction Performance}
\label{subsec:link_prediction_performance}

Table \ref{tab:link_prediction_performance} summarizes the performance of various models on the WN18RR and FB15k-237 datasets using standard link prediction metrics: Mean Reciprocal Rank (MRR) and Hits@K (K=1,3,10).

\begin{itemize}
    \item \textbf{Baseline}: The baseline model have an MRR of 0.387 on WN18RR and Hits@1 of 0.370. This serves as reference point.
    \item \textbf{Edge Dropout}: Introducing edge dropout with rates of 0.1 and 0.2 improves the MRR to 0.401 and 0.404 in the WN18RR and to 0.249 and 0.252 in FB15k-237, respectively. However, the improvement in Hits@1 is marginal. However, Hits@1 shows marginal improvement with 0.369 for WN18RR and for FB15k-237 it shows higher improvement with 0.157 and 0.159 respectively.
    \item \textbf{Label Smoothing}: Applying label smoothing with values of $\omega = 0.1$ and $\omega = 0.2$ yields MRRs of 0.411 and 0.403 for WN18RR, respectively. The Hits@1 metric also shows improvement, particularly with $\omega = 0.1$, reaching 0.387. While, for FB15K-237, the performance was totally opposite as MRR dropped to 0.219 and 0.2258 respectively and Hits@1 also dropped to 0.128 and 0.135 respectively. 
    \item \textbf{Combined Techniques}: For WN18RR, The best performance is observed when both edge dropout (0.2) and label smoothing (0.1) are combinely applied, achieving highest MRR of 0.440 and Hits@1 of 0.398. This combination yields highest scoress across all metrics, indicating a synergistic effect of the two regularization methods. However, for FB15k-237, the combined techniques was better than baseline and label smoothing but not better than edge dropout alone.
\end{itemize}


\begin{table}[htbp]
        \centering
        \includegraphics[width=\textwidth]{figures/experiment1/exp1table}
        \caption{Link Prediction Performance on WN18RR and FB15k-237 Datasets}
        \label{tab:link_prediction_performance}
\end{table}




\subsection{Uncertainty Metrics Analysis}
\label{subsec:uncertainty_metrics_analysis}

Figure \ref{tab:uncertainty_metrics_analysis} illustrates the impact of different regularization techniques on uncertainty estimation metrics, including Expected Calibration Error (ECE) and Reliability Diagram. Key observations include:
\begin{itemize}
    \item \textbf{Basline} shows the lowest ECE among all models, indicating better calibration compared to regularized models. This is counter intuitive as regularization is expected to improve calibration. Here both reliability diagrams have different trends. In WN18RR, it is overconfident in almost all ranges but in FB15K-237, it is underconfident in lower ranges and overconfident in higher ranges. Just like a logit function.

    \item \textbf{Edge Dropout} While in link prediction it improves the performance in both datasets, in uncertainty estimation it degrades the calibration with increasing dropout rates. In WN18RR, for Edge Dropout 0, ECE is 0.301, for 0.1 it is 0.374 and for 0.2 it is 0.388. In FB15K-237, for Edge Dropout 0, ECE is 0.1341, for 0.1 it is 0.1479 and for 0.2 it is 0.1654. Green and Blue lines shows edge dropout models in reliability diagram. They are also almost identical and follows same function as baseline.

    \item \textbf{Label Smoothing} Label smoothing also leads to higher ECE values compared to the baseline. For WN18RR,  The model with $\omega = 0.1$ has an ECE of 0.383, while $\omega = 0.2$ results in an ECE of 0.381. For FB15K-237, the model with $\omega = 0.1$ has an ECE of 0.3912, while $\omega = 0.2$ results in an ECE of 0.4079. Purple and Yellow lines shows label smoothing models and they are way off as compared to other. Our model for both datasets is exteremely skewed to lower confidence predictions and always predicts low confidence. Therefore we can see a horizonatl line near x = 0 in reliability diagram.

    \item \textbf{Combined Techniques} The combination of edge dropout (0.2) and label smoothing (0.1) results in the highest ECE of 0.3965 and 0.4222, indicating the poorest calibration among all configurations tested. The yellow line in reliability diagram shows the combined model. As we can see it is exactly overlapping with label smoothing models showing similar trend.
\end{itemize}

\begin{table}[htbp]
        \centering
        \includegraphics[width=0.75\textwidth]{figures/experiment1/exp1graph2}
        \includegraphics[width=0.75\textwidth]{figures/experiment1/exp1graph3}
        \caption{Uncertainty Metrics Analysis on WN18RR and FB15K-237 Datasets with Different Regularization Techniques. Here Edge Dropout is denoted as ED and Label Smoothing as LS.}
        \label{tab:uncertainty_metrics_analysis}
\end{table}

\section{Experiment 2: Uncertainty Estimation Methods}
\label{sec:experiment_2_uncertainty_estimation_methods}

This section presents the results of Experiment 2, which evaluates monte carlo dropout (MC Dropout) and deep ensembles as uncertainty estimation methods applied to the best performing regularized RGCN model from Experiment 1 - For WN18RR, Baseline + ED + LS and For FB15K-237, Baseline + ED. The performance and uncertainty estimation metrics are compared against the baseline regularized model without uncertainty estimation.

\subsection{Link Prediction Performance}
\label{subsec:link_prediction_performance_exp2}
Table \ref{tab:link_prediction_performance_exp2} summarizes the link prediction performance of the uncertainty estimation methods on the WN18RR and FB15k-237 datasets. Key observations include:

\begin{itemize}
        \item \textbf{Impact of } 
        \item \textbf{Basline} 
        \item \textbf{Basline} 
        \item \textbf{Basline} 
\end{itemize} 

\begin{table}[htbp]
        \centering
        \includegraphics[width=1\textwidth]{figures/experiment2/table}
        \caption{Link prediction performance of Uncertainty Estimation Methods on WN18RR and FB15k-237 Datasets}
        \label{tab:link_prediction_performance_exp2}
\end{table}


\subsection{Reliability Diagrams}
\label{subsec:reliability_diagrams}

Here are the description of the reliability diagrams for WN18RR and FB15K-237 datasets with different uncertainty estimation methods:

\begin{table}[htbp]
        \centering
        \includegraphics[width=0.75\textwidth]{figures/experiment2/graph_wrr}
        \includegraphics[width=0.75\textwidth]{figures/experiment2/graph_fb15}
        \caption{Uncertainty Metrics Analysis on WN18RR and FB15K-237 Datasets with Different Uncertainty Estimation Methods. Here Edge Dropout is denoted as ED and Label Smoothing as LS.}
        \label{tab:uncertainty_metrics_analysis_exp2}
\end{table}


\subsection{Computational Overhead (OPTIONAL)}
\label{subsec:computational_overhead}

\section{Experiment 3: Calibration Methods}
\label{sec:experiment_3_calibration_methods}

\subsection{Impact on ECE and ACE}
\label{subsec:impact_on_ece_and_ace}

\subsection{Qualitative Case Studies (OPTIONAL)}
\label{subsec:qualitative_case_studies}

\section{Experiment 4: Hybrid Approaches}
\label{sec:experiment_4_hybrid_approaches}

\subsection{Best Combined Configurations}
\label{subsec:best_combined_configurations}
